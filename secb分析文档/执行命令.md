执行方法

  1. 运行特定范围的实例

  # 运行前 10 个实例
  ./run_secb.sh poc -l :10

  # 运行第 5 到第 10 个实例
  ./run_secb.sh poc -l 5:10

  # 运行单个实例（例如第 3 个，索引从 0 开始）
  ./run_secb.sh poc -l 2:3

  2. 完整示例

  # PoC 模式，使用 sonnet 模型，运行前 5 个实例
  ./run_secb.sh poc -m sonnet -l :5

  # Patch 模式，使用 4o 模型，运行第 10-20 个实例，2 个 worker
  ./run_secb.sh patch -m 4o -l 10:20 -w 2

  # 运行单个实例（第 15 个），提高 cost limit
  ./run_secb.sh poc -l 14:15 -c 3.0

  3. 主要参数说明

  - 模式: poc 或 patch（必需）
  - -m: 模型（sonnet, haiku, 4o, o3, gemini-pro, human, deepseek）
  - -l: Slice 切片（格式：start:end）
  - -w: Worker 数量（并行处理）
  - -c: Cost limit（成本限制）
  - -n: 每个实例的调用次数限制

  4. 如何更换/添加新模型

  ## 4.1 使用现有模型

  脚本支持以下预配置模型：
  - `sonnet`: Claude 3.7 Sonnet
  - `haiku`: Claude 3 Haiku
  - `4o`: GPT-4o
  - `o3`: GPT-o3
  - `gemini-pro`: Gemini 2.5 Pro
  - `deepseek`: DeepSeek Chat（通过 API 聚合平台）
  - `human`: 人工交互模式

  使用示例：
  ```bash
  ./run_secb.sh poc -m deepseek
  ```

  ## 4.2 添加新的 API 聚合平台模型

  如果使用 API 聚合平台（如 dmxapi），需要配置：

  ### 步骤 1: 检查 litellm 是否原生支持模型

  首先测试模型是否支持 function calling（在 sweagent conda 环境中）：
  ```bash
  conda activate sweagent
  python -c "import litellm; print(litellm.utils.supports_function_calling(model='your-model-name'))"
  ```

  尝试不同的模型名称格式：
  - `model-name`
  - `provider/model-name`
  - `openai/model-name`

  找到返回 `True` 的格式。

  ### 步骤 2: 修改 run_secb.sh

  在脚本的模型映射部分（约第 90-110 行）添加新模型：
  ```bash
  elif [ "$model" == "your-model-name" ]; then
      model_name="provider/model-name"  # 使用支持 FC 的格式
      api_base="https://your-api-base.com/v1"
  ```

  ### 步骤 3: 配置 API Key

  在 `.env` 文件中添加对应的 API key。

  **注意**：环境变量名称取决于模型名称格式：
  - 如果使用 `provider/model` 格式（如 `deepseek/deepseek-chat`），需要 `PROVIDER_API_KEY`
  - 如果使用 `openai/model` 格式，使用 `OPENAI_API_KEY`
  - 如果使用标准 OpenAI 模型名（如 `gpt-4o`），使用 `OPENAI_API_KEY`

  ```bash
  # 示例 1: DeepSeek 模型使用 deepseek/ 前缀
  DEEPSEEK_API_KEY=your-api-key-here

  # 示例 2: 如果使用 openai/ 前缀或标准模型
  OPENAI_API_KEY=your-api-key-here
  ```

  ### 步骤 4: （可选）如果模型不支持 function calling

  如果所有格式都返回 `False`，需要使用 `custom_llm_provider`：

  编辑 `config/secb_poc.yaml` 或 `config/secb_patch.yaml`：
  ```yaml
  agent:
    model:
      completion_kwargs:
        custom_llm_provider: provider-name
    templates:
      # ... 其他配置
  ```

  ### 示例：DeepSeek 配置

  **测试结果**：
  ```bash
  # deepseek-chat: False (不支持)
  # deepseek/deepseek-chat: True (支持！)
  ```

  **run_secb.sh** (已配置)：
  ```bash
  elif [ "$model" == "deepseek" ]; then
      model_name="deepseek/deepseek-chat"  # 使用 provider/model 格式
      api_base="https://www.dmxapi.cn/v1"
  ```

  **不需要修改配置文件**，因为 litellm 原生支持该格式。

  **.env**：
  ```bash
  # 使用 deepseek/ 前缀时需要 DEEPSEEK_API_KEY
  DEEPSEEK_API_KEY=sk-your-deepseek-key
  ```

  5. 查看帮助

  ./run_secb.sh -h

  脚本会调用 sweagent run-batch 命令，使用 SEC-bench 数据集。如果你需要更精确的实例控制（例如通过实例 ID
  而不是索引），可能需要修改脚本或直接使用 sweagent run 命令来处理单个实例。